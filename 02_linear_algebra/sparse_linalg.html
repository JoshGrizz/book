

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Sparse Linear Algebra &#8212; Scientific Computing with Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Linear Algebra in PyTorch" href="pytorch.html" />
    <link rel="prev" title="Linear Operators" href="linearoperators.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Scientific Computing with Python</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_python/python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_analysis/analysis.html">
   Analysis of Algorithms
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="linear_algebra.html">
   Linear Algebra
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="memory.html">
     Memory and Performance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="numpy_scipy_linalg.html">
     Dense Linear Algebra in NumPy and SciPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="blas_lapack.html">
     BLAS and LAPACK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sparse.html">
     Sparse Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linearoperators.html">
     Linear Operators
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Sparse Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pytorch.html">
     Linear Algebra in PyTorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03_optimization/optimization.html">
   Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_functions/functions.html">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05_graphs/graphs.html">
   Graphs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06_probability_statistics/prob_stat.html">
   Probability and Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../07_data/data.html">
   Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08_geometry/geometry.html">
   Geometry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09_computing/computing.html">
   Computing
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/02_linear_algebra/sparse_linalg.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/caam37830/book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/caam37830/book/issues/new?title=Issue%20on%20page%20%2F02_linear_algebra/sparse_linalg.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/caam37830/book/master?urlpath=tree/02_linear_algebra/sparse_linalg.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/caam37830/book/blob/master/02_linear_algebra/sparse_linalg.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sparse-direct-methods">
   Sparse Direct Methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sparse-iterative-methods">
   Sparse Iterative Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparse-direct-vs-iterative-methods">
     Sparse Direct vs. Iterative Methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preconditioning">
     Preconditioning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#eigenvalues-and-eigenvectors">
   Eigenvalues and Eigenvectors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#randomized-linear-algebra">
   Randomized Linear Algebra
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="sparse-linear-algebra">
<h1>Sparse Linear Algebra<a class="headerlink" href="#sparse-linear-algebra" title="Permalink to this headline">¶</a></h1>
<p>So far, we have seen how sparse matrices and linear operators can be used to speed up basic matrix-vector and matrix-matrix operations, and decrease the memory footprint of the representation of a linear map.</p>
<p>Just as there are special data types for sparse and structured matrices, there are specialized linear algebra routines which allow you to take advantage of sparsity and fast matrix-vector products.</p>
<p>Routines for sparse linear algebra are found in <code class="docutils literal notranslate"><span class="pre">scipy.sparse.linalg</span></code>, which we’ll import as <code class="docutils literal notranslate"><span class="pre">sla</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sparse</span>
<span class="kn">import</span> <span class="nn">scipy.sparse.linalg</span> <span class="k">as</span> <span class="nn">sla</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Populating the interactive namespace from numpy and matplotlib
</pre></div>
</div>
</div>
</div>
<div class="section" id="sparse-direct-methods">
<h2>Sparse Direct Methods<a class="headerlink" href="#sparse-direct-methods" title="Permalink to this headline">¶</a></h2>
<p>This typically refers to producing a factorization of a sparse matrix for use in solving linear systems.</p>
<p>The thing to keep in mind is that many factorizations will generally be dense, even if the original matrix is sparse.  E.g. eigenvalue decompositions, QR decomposition, SVD, etc.  This means that if we compute a factorization, we are going to lose all the advantages we had from sparsity.</p>
<p>What we really want is a factorization where if <code class="docutils literal notranslate"><span class="pre">A</span></code> is sparse, the terms in the factorization are also sparse.  The factorization where this is easiest to achieve is the LU decomposition.  In general, the <code class="docutils literal notranslate"><span class="pre">L</span></code> and <code class="docutils literal notranslate"><span class="pre">U</span></code> terms will be more dense than <code class="docutils literal notranslate"><span class="pre">A</span></code>, and sometimes much more dense.  However, we can seek a permuted version of the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> which will minimize the amount of “fill-in” which occurs.  This is often done using “nested disection” algorithm, which is outside the scope of this course.  If you ever need to do this explicitly, the <a class="reference external" href="http://glaros.dtc.umn.edu/gkhome/metis/metis/overview">METIS package</a> is commonly used.</p>
<p>We’ll just use the function <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.splu.html#scipy.sparse.linalg.splu"><code class="docutils literal notranslate"><span class="pre">sla.splu</span></code></a> (SParse LU) at a high level, which produces a factorization object that can be used to solve linear systems.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span> <span class="o">+</span> <span class="n">sparse</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">spy</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/sparse_linalg_3_0.png" src="../_images/sparse_linalg_3_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">tocsc</span><span class="p">()</span> <span class="c1"># need to convert to CSC form first</span>
<span class="n">LU</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">splu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">LU</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;SuperLU at 0x7f11becb8780&gt;
</pre></div>
</div>
</div>
</div>
<p>The resulting object stores the factors necessary to compute <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">PLUQ</span></code> (<code class="docutils literal notranslate"><span class="pre">P</span></code> permutes rows, and <code class="docutils literal notranslate"><span class="pre">Q</span></code> permutes columns).  It is computed using the <a class="reference external" href="https://portal.nersc.gov/project/sparse/superlu/">SuperLU library</a>.  Typically, you will just use the <code class="docutils literal notranslate"><span class="pre">solve</span></code> method on this object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">x</span>

<span class="n">x2</span> <span class="o">=</span> <span class="n">LU</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>8.231082667203162e-16
</pre></div>
</div>
</div>
</div>
<p>you can also use the <code class="docutils literal notranslate"><span class="pre">sla.spsolve</span></code> function, which wraps this factorization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">spsolve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>8.231082667203162e-16
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sparse-iterative-methods">
<h2>Sparse Iterative Methods<a class="headerlink" href="#sparse-iterative-methods" title="Permalink to this headline">¶</a></h2>
<p>Sparse iterative methods are another class of methods you can use for solving linear systems built on <a class="reference external" href="https://en.wikipedia.org/wiki/Krylov_subspace">Krylov subspaces</a>.  They only require matrix-vector products, and are ideally used with sparse matrices and fast linear operators.  You can typically learn the theory behind these methods in a numerical linear algebra course - we’ll just talk about how to use them.</p>
<p>All these methods are meant to solve linear systems: find <code class="docutils literal notranslate"><span class="pre">x</span></code> so that <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">b</span></code>, or least squares problems minimizing <code class="docutils literal notranslate"><span class="pre">norm(A</span> <span class="pre">&#64;</span> <span class="pre">x</span> <span class="pre">-</span> <span class="pre">b)</span></code></p>
<p>You can find a list of options in the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/sparse.linalg.html#solving-linear-problems">documentation for <code class="docutils literal notranslate"><span class="pre">scipy.sparse.linalg</span></code></a>.  Here are some common options:</p>
<ul class="simple">
<li><p>Conjugate Gradient: <code class="docutils literal notranslate"><span class="pre">sla.cg</span></code> for <code class="docutils literal notranslate"><span class="pre">A</span></code> SPD</p></li>
<li><p>MINRES: <code class="docutils literal notranslate"><span class="pre">sla.minres</span></code> for <code class="docutils literal notranslate"><span class="pre">A</span></code> symmetric</p></li>
<li><p>GMRES: <code class="docutils literal notranslate"><span class="pre">sla.gmres</span></code> for general square <code class="docutils literal notranslate"><span class="pre">A</span></code></p></li>
<li><p>LSQR: <code class="docutils literal notranslate"><span class="pre">sla.lsqr</span></code> for solving least squares problems</p></li>
</ul>
<p>For example, we can use <code class="docutils literal notranslate"><span class="pre">gmres</span></code> with the same matrix we used for <code class="docutils literal notranslate"><span class="pre">splu</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span> <span class="c1"># exit code: 0 if successful</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>8.141629111877278e-09
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GMRES in </span><span class="si">{}</span><span class="s2"> sec.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">spsolve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;spsolve in </span><span class="si">{}</span><span class="s2"> sec.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>GMRES in 0.0013661384582519531 sec.
spsolve in 0.0008120536804199219 sec.
</pre></div>
</div>
</div>
</div>
<div class="section" id="sparse-direct-vs-iterative-methods">
<h3>Sparse Direct vs. Iterative Methods<a class="headerlink" href="#sparse-direct-vs-iterative-methods" title="Permalink to this headline">¶</a></h3>
<p>There are a couple of trade offs to consider when deciding whether to use sparse direct or iterative algorithms.</p>
<ol class="simple">
<li><p>Are you going to be solving many linear systems with the same matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>?  If so, you can produce a single factorization object using <code class="docutils literal notranslate"><span class="pre">splu</span></code>, and use it to solve many right-hand sides.  Sparse direct probably makes more sense.</p></li>
<li><p>Are you solving a single linear system?  If so, then a single call to an iterative method probably makes mores sense.</p></li>
<li><p>Are you using a fast linear operator that could be expressed as a dense matrix (e.g. sparse plus low-rank)?  Alternatively, would the sparse LU decomposition turn dense because of fill-in?  If so, then iterative methods probably make more sense.</p></li>
<li><p>Do you have a really good preconditioner (see below)?  Then iterative methods probably make more sense.</p></li>
</ol>
</div>
<div class="section" id="preconditioning">
<h3>Preconditioning<a class="headerlink" href="#preconditioning" title="Permalink to this headline">¶</a></h3>
<p>The speed/effectiveness of iterative methods is often dependent on the existence of a good preconditioner. A preconditioner <code class="docutils literal notranslate"><span class="pre">M</span></code> for a matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is an “approximate inverse” i.e. <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">&#64;</span> <span class="pre">A</span></code> is close to the identity.  Note if we had an exact inverse, we’ve solved our problem already.  What we want is to have a matrix <code class="docutils literal notranslate"><span class="pre">M</span></code> which is fast to apply (i.e. also sparse like <code class="docutils literal notranslate"><span class="pre">A</span></code>), which generally isn’t possible with an exact inverse.</p>
<p>Finding a good preconditioner is a huge field of research, and can be very domain-dependent.  A general-purpose method to obtain a preconditioner is to use an Incomplete LU decomposition (this is an LU factorization that stops when the fill-in gets too large). You can obtain one using <code class="docutils literal notranslate"><span class="pre">sla.spilu</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ILUfact</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">spilu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can construct a preconditioner using a <code class="docutils literal notranslate"><span class="pre">LinearOperator</span></code> around the ILU object’s solve method</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">M</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">LinearOperator</span><span class="p">(</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
    <span class="n">matvec</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="n">ILUfact</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">)</span> <span class="c1"># exit code: 0 if successful</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>1.2443960745566972e-15
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GMRES in </span><span class="si">{}</span><span class="s2"> sec.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;preconditioned GMRES in </span><span class="si">{}</span><span class="s2"> sec.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>GMRES in 0.0010304450988769531 sec.
9.070074360540128e-05
preconditioned GMRES in 0.0007236003875732422 sec.
1.2443960745566972e-15
</pre></div>
</div>
</div>
</div>
<p>We get a higher-precision answer in about the same amount of time.</p>
</div>
</div>
<div class="section" id="eigenvalues-and-eigenvectors">
<h2>Eigenvalues and Eigenvectors<a class="headerlink" href="#eigenvalues-and-eigenvectors" title="Permalink to this headline">¶</a></h2>
<p>Computing a full eigenvalue decomposition of a sparse matrix or fast linear operator doesn’t typically make sense (see the the discussion for sparse direct methods).  However, there are a lot of situations in which we want to compute the eigenvalue-eigenvector pairs for a handful of the largest (or smallest) eigenvalues.</p>
<p><code class="docutils literal notranslate"><span class="pre">scipy.sparse.linalg</span></code> wraps <a class="reference external" href="https://www.caam.rice.edu/software/ARPACK/">ARPACK (ARnoldi PACKage)</a>, which uses Krylov subspace techniques (like the iterative methods) to compute eigenvalues/eigenvectors using matrix-vector multiplications.  The relevant methods are <code class="docutils literal notranslate"><span class="pre">sla.eigs</span></code> (for general square matrices) and <code class="docutils literal notranslate"><span class="pre">sla.eigsh</span></code> (for symmetric/Hermitian matrices).  There is also a <code class="docutils literal notranslate"><span class="pre">sla.svds</span></code> function for the SVD.</p>
<p>Let’s look at an example for a linear operator which acts as the matrix of all ones.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># works on square matrices</span>
<span class="n">Afun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">m</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># linear operator of size 10</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">LinearOperator</span><span class="p">(</span>
    <span class="n">shape</span>   <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">),</span>
    <span class="n">matvec</span>  <span class="o">=</span> <span class="n">Afun</span><span class="p">,</span>
    <span class="n">rmatvec</span> <span class="o">=</span> <span class="n">Afun</span><span class="p">,</span>
    <span class="n">matmat</span>  <span class="o">=</span> <span class="n">Afun</span><span class="p">,</span>
    <span class="n">rmatmat</span> <span class="o">=</span> <span class="n">Afun</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span>   
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This operator is Hermitian, so we’ll use <code class="docutils literal notranslate"><span class="pre">eigsh</span></code>.  By default, <code class="docutils literal notranslate"><span class="pre">eigsh</span></code> will compute the largest magnitude eigenvalues.  You can change which eigenvalues you’re looking for using the <code class="docutils literal notranslate"><span class="pre">which</span></code> keyword argument, and the number of eigenvalues using the <code class="docutils literal notranslate"><span class="pre">k</span></code> argument.  See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.eigsh.html#scipy.sparse.linalg.eigsh">the documentation</a> for details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lam</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lam</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([-5.86174617e-18, -3.50871500e-32,  2.38837756e-32,  2.87286167e-32,
        1.78221859e-15,  1.00000000e+01])
</pre></div>
</div>
</div>
</div>
<p>we see there is one eigenvalue with a numerically non-zero value (10).  Let’s take a look at the eigenvector</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">V</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([-0.31622777, -0.31622777, -0.31622777, -0.31622777, -0.31622777,
       -0.31622777, -0.31622777, -0.31622777, -0.31622777, -0.31622777])
</pre></div>
</div>
</div>
</div>
<p>this is the vector with constant entries.  This agrees with our understanding of the operator <code class="docutils literal notranslate"><span class="pre">A</span></code>, which can be expressed as the symmetric rank-1 outer product of the vector with 1s in every entry.</p>
</div>
<div class="section" id="randomized-linear-algebra">
<h2>Randomized Linear Algebra<a class="headerlink" href="#randomized-linear-algebra" title="Permalink to this headline">¶</a></h2>
<p>In the past decade or two, randomized linear algebra has matured as a topic with lots of practical applications.  To read about the theory, see the 2009 paper by Halko, Martinsson, and Tropp: <a class="reference external" href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Link</a>.</p>
<p>SciPy does not (currently) have built-in functions for randomized linear algebra functionality (some languages like Julia do).  Fortunately, these algorithms are very easy to implement without worrying too much about the theory.</p>
<p>For simplicity, we’ll assume that <code class="docutils literal notranslate"><span class="pre">A</span></code> is symmetric with distinct eigenvectors, so we can limit the discussion to eigenvectors.  A rank-<code class="docutils literal notranslate"><span class="pre">k</span></code> approximation of <code class="docutils literal notranslate"><span class="pre">A</span></code> is an approximation by a rank-<code class="docutils literal notranslate"><span class="pre">k</span></code> outer product.  We can analyitically obtain the optimal rank-<code class="docutils literal notranslate"><span class="pre">k</span></code> approximation by computing a full eigenvalue decomposition of <code class="docutils literal notranslate"><span class="pre">A</span></code> and set all the eigenvalues outside the largest <code class="docutils literal notranslate"><span class="pre">k</span></code> (in magnitude) to 0.  Again, we don’t want to actually compute the full eigenvalue decomposition, so we want an algorithm that does this in some provable way.</p>
<p>The basic idea is to get an approximation of the range of an operator <code class="docutils literal notranslate"><span class="pre">A</span></code> by applying it to a bunch of random vectors. That is, we compute <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">X</span></code>, where <code class="docutils literal notranslate"><span class="pre">X</span></code> is a matrix with random entries (we think of every column as a random vector). One way to think about the action of <code class="docutils literal notranslate"><span class="pre">A</span></code> is that it “rotates” these random vectors preferentially in the direction of the top eigenvectors, so if we look at the most important subspace of the span of the image  <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">X</span></code> (as measured by the svd), we get a good approximation of the most important eigenspace.</p>
<p>Randomized algorithms have probabilistic gurarantees.  The statement is roughly that if entries of <code class="docutils literal notranslate"><span class="pre">X</span></code> are iid sub-Gaussian random variables (you can replace “sub-Gaussian” with Gaussian), and if we use <code class="docutils literal notranslate"><span class="pre">k+p</span></code> random vectors (<code class="docutils literal notranslate"><span class="pre">p</span></code> is a small constant), we can get close to the top-<code class="docutils literal notranslate"><span class="pre">k</span></code> dimensional eigenspace <em>with high probability</em>.  In this case, <em>close</em> depends on something called the spectral gap, and <em>with high probability</em> means that in order to <strong>not</strong> be close to the desired subspace you would likely need to keep running computations with different random numbers for millions or billions of years before you would observe the algorithm fail.</p>
<p>Let’s see how this works in practice:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.linalg</span> <span class="k">as</span> <span class="nn">la</span>

<span class="k">def</span> <span class="nf">random_span_k</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute subspace whose span is close to contaning the top-k eigenspace of A</span>
<span class="sd">    </span>
<span class="sd">    p = number of dimensions to pad</span>
<span class="sd">    power : number of times to run a power iteration on the subspace</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span>
        
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="n">p</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">X</span>
    
    <span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">power</span><span class="p">):</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">U</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    
    <span class="k">return</span> <span class="n">U</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s test this on a diagonal matrix with entries 0 to <code class="docutils literal notranslate"><span class="pre">n-1</span></code> along the main diagonal.  In this case, the eigenvalues are integers, and the eigenvectors are the standard basis vectors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">dia_matrix</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>
<span class="n">D</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;100x100 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 100 stored elements (1 diagonals) in DIAgonal format&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">random_span_k</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lam</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>
<span class="n">V_true</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span><span class="o">-</span><span class="n">k</span><span class="p">:]</span>
<span class="n">V_true</span><span class="p">[</span><span class="o">-</span><span class="n">k</span><span class="p">:,:]</span> <span class="c1"># should see identity</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 1.]])
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at how well <code class="docutils literal notranslate"><span class="pre">U</span></code> captures each eigenvector.  The distance from this subspace from the <code class="docutils literal notranslate"><span class="pre">i</span></code>th eigenvector is <code class="docutils literal notranslate"><span class="pre">norm(V[:,i].T*U)</span></code>.  Because the eigenvectors are canonical basis vectors, this is just the norm of the <code class="docutils literal notranslate"><span class="pre">i</span></code>th row of <code class="docutils literal notranslate"><span class="pre">U</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:02d}</span><span class="s2"> : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>00 : 1.3753633400861164e-16
01 : 0.008422116050983038
02 : 0.02409794163113647
03 : 0.024425285868089057
04 : 0.03819215095867893
05 : 0.0426926818899043
06 : 0.04900577637623012
07 : 0.06483327587725622
08 : 0.04751572310874468
09 : 0.05969921246699562
10 : 0.10489771656939825
11 : 0.0862457901164299
12 : 0.13062482148738447
13 : 0.12693924248492036
14 : 0.10932894427997215
15 : 0.08909181939064331
16 : 0.15936518443340436
17 : 0.18675325205905244
18 : 0.09350178320022128
19 : 0.1576065891287464
20 : 0.11383179816780935
21 : 0.18263836569320457
22 : 0.1787714551687548
23 : 0.18972652831368628
24 : 0.13506203582119275
25 : 0.18900652122925715
26 : 0.255121777375825
27 : 0.20336470885370347
28 : 0.22969784627673176
29 : 0.187722146945506
30 : 0.3437330884001671
31 : 0.26607594153338676
32 : 0.21430069994545947
33 : 0.2921122347543295
34 : 0.26470743474660413
35 : 0.21873778944503353
36 : 0.3196343742666097
37 : 0.26742425821471755
38 : 0.32156330753485796
39 : 0.30854394948911096
40 : 0.25128285255879346
41 : 0.30559625197437074
42 : 0.2909455011735765
43 : 0.32960946312249934
44 : 0.28119650517534667
45 : 0.30519565597266973
46 : 0.2892129057558176
47 : 0.4669499455766619
48 : 0.30795964672945003
49 : 0.4131935663393777
50 : 0.4651128001750668
51 : 0.3920007865245876
52 : 0.4240681750076058
53 : 0.39172129496758007
54 : 0.3725447283964597
55 : 0.3184113293011414
56 : 0.37058508853776484
57 : 0.41771138751411324
58 : 0.3875300318328056
59 : 0.4304368138221574
60 : 0.45834424839530236
61 : 0.32954544380383066
62 : 0.405568029647865
63 : 0.3910527531288001
64 : 0.40672292088327805
65 : 0.44620973135611647
66 : 0.5051000556454319
67 : 0.630939694899218
68 : 0.34053111882183357
69 : 0.31235366268237386
70 : 0.4737998587757871
71 : 0.5352888343301037
72 : 0.4534039626424533
73 : 0.43028171104003926
74 : 0.4609807661754064
75 : 0.5160684054619503
76 : 0.46432481197204156
77 : 0.6406044545082389
78 : 0.5927547026236478
79 : 0.4777480586364657
80 : 0.47725705197264284
81 : 0.5673972558803722
82 : 0.5809913358664536
83 : 0.47273273205104505
84 : 0.5247639558722481
85 : 0.6740709945448125
86 : 0.5863217580695821
87 : 0.5162231556678072
88 : 0.47179541662436913
89 : 0.49957439009413385
90 : 0.527785495371574
91 : 0.5792201637858888
92 : 0.5112082322621725
93 : 0.5411720245417876
94 : 0.648605825959637
95 : 0.6811588182248363
96 : 0.5321644233322905
97 : 0.6862337586582326
98 : 0.5679048738793608
99 : 0.6772150165745402
</pre></div>
</div>
</div>
</div>
<p>As we see, <code class="docutils literal notranslate"><span class="pre">U</span></code> is closer to the larger eigenvectors, rather than the smaller eigenvectors.</p>
<p>We can improve this estimate by running a couple of power iterations on the subspace (the <code class="docutils literal notranslate"><span class="pre">power</span></code> keyword defined above):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">U</span> <span class="o">=</span> <span class="n">random_span_k</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:02d}</span><span class="s2"> : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>00 : 1.1136060022526339e-16
01 : 3.414632280650423e-12
02 : 2.865561247169124e-10
03 : 1.4855391642002577e-09
04 : 7.935060952527598e-09
05 : 6.431995134659886e-08
06 : 1.5692199209738648e-07
07 : 1.9580554500346756e-07
08 : 8.167952463402354e-07
09 : 1.7832165794835015e-06
10 : 2.6180402841510113e-06
11 : 5.978827554516885e-06
12 : 1.1034285272678945e-05
13 : 7.537135960117702e-06
14 : 2.5943811650594952e-05
15 : 4.8727416980930656e-05
16 : 4.720785830566772e-05
17 : 3.4718252981890856e-05
18 : 7.936399668773552e-05
19 : 0.00017680503088422287
20 : 0.00020333629106003524
21 : 0.00024967276244902323
22 : 0.000285087803001346
23 : 0.0007946165933681899
24 : 0.0007613583869822541
25 : 0.0007731760493586393
26 : 0.0005493808565848403
27 : 0.0010968928262756617
28 : 0.001367047169567966
29 : 0.001664680156094179
30 : 0.0025758208848149725
31 : 0.003032655977728242
32 : 0.003097297734023321
33 : 0.003009974518950732
34 : 0.005096759222816761
35 : 0.005305367516149181
36 : 0.007583910912816749
37 : 0.01104291655645618
38 : 0.00889301709854682
39 : 0.009289821512451637
40 : 0.009714146805295336
41 : 0.013575240053372344
42 : 0.01453623087738317
43 : 0.012957986323519114
44 : 0.015732331104509382
45 : 0.023699728566508458
46 : 0.06558728380285972
47 : 0.02613193646839366
48 : 0.028097834167553307
49 : 0.021499321055876007
50 : 0.03384527257312099
51 : 0.0484494773457778
52 : 0.05627111510175214
53 : 0.07436160960593866
54 : 0.07367844733034731
55 : 0.08406651568089082
56 : 0.12509170026627708
57 : 0.049319872609895336
58 : 0.14956923016862875
59 : 0.1194795387093889
60 : 0.1398758587959422
61 : 0.1918872592861698
62 : 0.138312470969656
63 : 0.10511638695695333
64 : 0.17643885267015813
65 : 0.2681070072399501
66 : 0.28507553854565904
67 : 0.33959743884797255
68 : 0.2966081755638791
69 : 0.2408318008466496
70 : 0.2497067079050986
71 : 0.3859142209822045
72 : 0.4395173941742858
73 : 0.5498520714407967
74 : 0.35303785516821734
75 : 0.5613513935787195
76 : 0.5751664175169064
77 : 0.36660332871956264
78 : 0.3879566245972342
79 : 0.40188818538075377
80 : 0.34373238962786445
81 : 0.6327662138351361
82 : 0.6775602564115892
83 : 0.6555718863673102
84 : 0.6976336203832533
85 : 0.6822782691811656
86 : 0.7009209078819413
87 : 0.7640463889874051
88 : 0.6533735232645264
89 : 0.8584297624165603
90 : 0.8853693279004387
91 : 0.8219792609711676
92 : 0.8562298098691917
93 : 0.878952613584747
94 : 0.7690227419805704
95 : 0.9509200997252906
96 : 0.9123106833254468
97 : 0.867461622381632
98 : 0.9608838799344841
99 : 0.942915907107843
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p>Download a couple of test matrices from the UFlorida Sparse Matrix collection <a class="reference external" href="https://sparse.tamu.edu/">Link</a>
For, example, use <code class="docutils literal notranslate"><span class="pre">mnist_test_norm_10NN</span></code> <a class="reference external" href="https://sparse.tamu.edu/ML_Graph/mnist_test_norm_10NN">Link</a> which would probably be too large to store on your computer as a dense matrix.</p>
<p>For each square matrix:</p>
<ol class="simple">
<li><p>Solve a random linear system using <code class="docutils literal notranslate"><span class="pre">splu</span></code></p></li>
<li><p>Solve a random linear system using either <code class="docutils literal notranslate"><span class="pre">minres</span></code> or <code class="docutils literal notranslate"><span class="pre">gmres</span></code> (which one should you use?)</p></li>
<li><p>Compute the largest magnitude eigenvector using <code class="docutils literal notranslate"><span class="pre">eigs</span></code> or <code class="docutils literal notranslate"><span class="pre">eigsh</span></code> (which one should you use?)</p></li>
</ol>
<p>Find a non-square matrix and</p>
<ol class="simple">
<li><p>Solve a random least squares problem using <code class="docutils literal notranslate"><span class="pre">lsqr</span></code></p></li>
<li><p>Compute the largest singular vectors using <code class="docutils literal notranslate"><span class="pre">svds</span></code></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Your code here</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "pycourse"
        },
        kernelOptions: {
            kernelName: "pycourse",
            path: "./02_linear_algebra"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'pycourse'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="linearoperators.html" title="previous page">Linear Operators</a>
    <a class='right-next' id="next-link" href="pytorch.html" title="next page">Linear Algebra in PyTorch</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Brad Nelson<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>