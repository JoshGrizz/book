

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Sparse Linear Algebra &#8212; Scientific Computing with Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Linear Algebra in PyTorch" href="pytorch.html" />
    <link rel="prev" title="Linear Operators" href="linearoperators.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Scientific Computing with Python</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_python/python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_analysis/analysis.html">
   Analysis of Algorithms
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="linear_algebra.html">
   Linear Algebra
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="memory.html">
     Memory and Performance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="numpy_scipy_linalg.html">
     Dense Linear Algebra in NumPy and SciPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="blas_lapack.html">
     BLAS and LAPACK
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sparse.html">
     Sparse Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="linearoperators.html">
     Linear Operators
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Sparse Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pytorch.html">
     Linear Algebra in PyTorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03_optimization/optimization.html">
   Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_functions/functions.html">
   Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05_graphs/graphs.html">
   Graphs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06_probability_statistics/prob_stat.html">
   Probability and Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../07_data/data.html">
   Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08_geometry/geometry.html">
   Geometry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09_computing/computing.html">
   Computing
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/02_linear_algebra/sparse_linalg.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/caam37830/book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/caam37830/book/issues/new?title=Issue%20on%20page%20%2F02_linear_algebra/sparse_linalg.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/caam37830/book/master?urlpath=tree/02_linear_algebra/sparse_linalg.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/caam37830/book/blob/master/02_linear_algebra/sparse_linalg.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sparse-direct-methods">
   Sparse Direct Methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sparse-iterative-methods">
   Sparse Iterative Methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparse-direct-vs-iterative-methods">
     Sparse Direct vs. Iterative Methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preconditioning">
     Preconditioning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#eigenvalues-and-eigenvectors">
   Eigenvalues and Eigenvectors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#randomized-linear-algebra">
   Randomized Linear Algebra
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="sparse-linear-algebra">
<h1>Sparse Linear Algebra<a class="headerlink" href="#sparse-linear-algebra" title="Permalink to this headline">¶</a></h1>
<p>So far, we have seen how sparse matrices and linear operators can be used to speed up basic matrix-vector and matrix-matrix operations, and decrease the memory footprint of the representation of a linear map.</p>
<p>Just as there are special data types for sparse and structured matrices, there are specialized linear algebra routines which allow you to take advantage of sparsity and fast matrix-vector products.</p>
<p>Routines for sparse linear algebra are found in <code class="docutils literal notranslate"><span class="pre">scipy.sparse.linalg</span></code>, which we’ll import as <code class="docutils literal notranslate"><span class="pre">sla</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sparse</span>
<span class="kn">import</span> <span class="nn">scipy.sparse.linalg</span> <span class="k">as</span> <span class="nn">sla</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Populating the interactive namespace from numpy and matplotlib
</pre></div>
</div>
</div>
</div>
<div class="section" id="sparse-direct-methods">
<h2>Sparse Direct Methods<a class="headerlink" href="#sparse-direct-methods" title="Permalink to this headline">¶</a></h2>
<p>This typically refers to producing a factorization of a sparse matrix for use in solving linear systems.</p>
<p>The thing to keep in mind is that many factorizations will generally be dense, even if the original matrix is sparse.  E.g. eigenvalue decompositions, QR decomposition, SVD, etc.  This means that if we compute a factorization, we are going to lose all the advantages we had from sparsity.</p>
<p>What we really want is a factorization where if <code class="docutils literal notranslate"><span class="pre">A</span></code> is sparse, the terms in the factorization are also sparse.  The factorization where this is easiest to achieve is the LU decomposition.  In general, the <code class="docutils literal notranslate"><span class="pre">L</span></code> and <code class="docutils literal notranslate"><span class="pre">U</span></code> terms will be more dense than <code class="docutils literal notranslate"><span class="pre">A</span></code>, and sometimes much more dense.  However, we can seek a permuted version of the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> which will minimize the amount of “fill-in” which occurs.  This is often done using “nested disection” algorithm, which is outside the scope of this course.  If you ever need to do this explicitly, the <a class="reference external" href="http://glaros.dtc.umn.edu/gkhome/metis/metis/overview">METIS package</a> is commonly used.</p>
<p>We’ll just use the function <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.splu.html#scipy.sparse.linalg.splu"><code class="docutils literal notranslate"><span class="pre">sla.splu</span></code></a> (SParse LU) at a high level, which produces a factorization object that can be used to solve linear systems.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span> <span class="o">+</span> <span class="n">sparse</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">spy</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/sparse_linalg_3_0.png" src="../_images/sparse_linalg_3_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">tocsc</span><span class="p">()</span> <span class="c1"># need to convert to CSC form first</span>
<span class="n">LU</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">splu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">LU</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;SuperLU at 0x7f76c17bb300&gt;
</pre></div>
</div>
</div>
</div>
<p>The resulting object stores the factors necessary to compute <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">=</span> <span class="pre">PLUQ</span></code> (<code class="docutils literal notranslate"><span class="pre">P</span></code> permutes rows, and <code class="docutils literal notranslate"><span class="pre">Q</span></code> permutes columns).  It is computed using the <a class="reference external" href="https://portal.nersc.gov/project/sparse/superlu/">SuperLU library</a>.  Typically, you will just use the <code class="docutils literal notranslate"><span class="pre">solve</span></code> method on this object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">x</span>

<span class="n">x2</span> <span class="o">=</span> <span class="n">LU</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>8.854110870823577e-16
</pre></div>
</div>
</div>
</div>
<p>you can also use the <code class="docutils literal notranslate"><span class="pre">sla.spsolve</span></code> function, which wraps this factorization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">spsolve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>8.854110870823577e-16
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sparse-iterative-methods">
<h2>Sparse Iterative Methods<a class="headerlink" href="#sparse-iterative-methods" title="Permalink to this headline">¶</a></h2>
<p>Sparse iterative methods are another class of methods you can use for solving linear systems built on <a class="reference external" href="https://en.wikipedia.org/wiki/Krylov_subspace">Krylov subspaces</a>.  They only require matrix-vector products, and are ideally used with sparse matrices and fast linear operators.  You can typically learn the theory behind these methods in a numerical linear algebra course - we’ll just talk about how to use them.</p>
<p>All these methods are meant to solve linear systems: find <code class="docutils literal notranslate"><span class="pre">x</span></code> so that <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">x</span> <span class="pre">=</span> <span class="pre">b</span></code>, or least squares problems minimizing <code class="docutils literal notranslate"><span class="pre">norm(A</span> <span class="pre">&#64;</span> <span class="pre">x</span> <span class="pre">-</span> <span class="pre">b)</span></code></p>
<p>You can find a list of options in the <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/sparse.linalg.html#solving-linear-problems">documentation for <code class="docutils literal notranslate"><span class="pre">scipy.sparse.linalg</span></code></a>.  Here are some common options:</p>
<ul class="simple">
<li><p>Conjugate Gradient: <code class="docutils literal notranslate"><span class="pre">sla.cg</span></code> for <code class="docutils literal notranslate"><span class="pre">A</span></code> SPD</p></li>
<li><p>MINRES: <code class="docutils literal notranslate"><span class="pre">sla.minres</span></code> for <code class="docutils literal notranslate"><span class="pre">A</span></code> symmetric</p></li>
<li><p>GMRES: <code class="docutils literal notranslate"><span class="pre">sla.gmres</span></code> for general square <code class="docutils literal notranslate"><span class="pre">A</span></code></p></li>
<li><p>LSQR: <code class="docutils literal notranslate"><span class="pre">sla.lsqr</span></code> for solving least squares problems</p></li>
</ul>
<p>For example, we can use <code class="docutils literal notranslate"><span class="pre">gmres</span></code> with the same matrix we used for <code class="docutils literal notranslate"><span class="pre">splu</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span> <span class="c1"># exit code: 0 if successful</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>3.497984390648174e-08
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GMRES in </span><span class="si">{}</span><span class="s2"> sec.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">spsolve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;spsolve in </span><span class="si">{}</span><span class="s2"> sec.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>GMRES in 0.0010235309600830078 sec.
spsolve in 0.0007042884826660156 sec.
</pre></div>
</div>
</div>
</div>
<div class="section" id="sparse-direct-vs-iterative-methods">
<h3>Sparse Direct vs. Iterative Methods<a class="headerlink" href="#sparse-direct-vs-iterative-methods" title="Permalink to this headline">¶</a></h3>
<p>There are a couple of trade offs to consider when deciding whether to use sparse direct or iterative algorithms.</p>
<ol class="simple">
<li><p>Are you going to be solving many linear systems with the same matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>?  If so, you can produce a single factorization object using <code class="docutils literal notranslate"><span class="pre">splu</span></code>, and use it to solve many right-hand sides.  Sparse direct probably makes more sense.</p></li>
<li><p>Are you solving a single linear system?  If so, then a single call to an iterative method probably makes mores sense.</p></li>
<li><p>Are you using a fast linear operator that could be expressed as a dense matrix (e.g. sparse plus low-rank)?  Alternatively, would the sparse LU decomposition turn dense because of fill-in?  If so, then iterative methods probably make more sense.</p></li>
<li><p>Do you have a really good preconditioner (see below)?  Then iterative methods probably make more sense.</p></li>
</ol>
</div>
<div class="section" id="preconditioning">
<h3>Preconditioning<a class="headerlink" href="#preconditioning" title="Permalink to this headline">¶</a></h3>
<p>The speed/effectiveness of iterative methods is often dependent on the existence of a good preconditioner. A preconditioner <code class="docutils literal notranslate"><span class="pre">M</span></code> for a matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is an “approximate inverse” i.e. <code class="docutils literal notranslate"><span class="pre">M</span> <span class="pre">&#64;</span> <span class="pre">A</span></code> is close to the identity.  Note if we had an exact inverse, we’ve solved our problem already.  What we want is to have a matrix <code class="docutils literal notranslate"><span class="pre">M</span></code> which is fast to apply (i.e. also sparse like <code class="docutils literal notranslate"><span class="pre">A</span></code>), which generally isn’t possible with an exact inverse.</p>
<p>Finding a good preconditioner is a huge field of research, and can be very domain-dependent.  A general-purpose method to obtain a preconditioner is to use an Incomplete LU decomposition (this is an LU factorization that stops when the fill-in gets too large). You can obtain one using <code class="docutils literal notranslate"><span class="pre">sla.spilu</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ILUfact</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">spilu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can construct a preconditioner using a <code class="docutils literal notranslate"><span class="pre">LinearOperator</span></code> around the ILU object’s solve method</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">M</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">LinearOperator</span><span class="p">(</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
    <span class="n">matvec</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="n">ILUfact</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">)</span> <span class="c1"># exit code: 0 if successful</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>1.0043689391289252e-15
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GMRES in </span><span class="si">{}</span><span class="s2"> sec.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">exit</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">gmres</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;preconditioned GMRES in </span><span class="si">{}</span><span class="s2"> sec.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>GMRES in 0.0009131431579589844 sec.
0.0001092742643454168
preconditioned GMRES in 0.0010290145874023438 sec.
1.0043689391289252e-15
</pre></div>
</div>
</div>
</div>
<p>We get a higher-precision answer in about the same amount of time.</p>
</div>
</div>
<div class="section" id="eigenvalues-and-eigenvectors">
<h2>Eigenvalues and Eigenvectors<a class="headerlink" href="#eigenvalues-and-eigenvectors" title="Permalink to this headline">¶</a></h2>
<p>Computing a full eigenvalue decomposition of a sparse matrix or fast linear operator doesn’t typically make sense (see the the discussion for sparse direct methods).  However, there are a lot of situations in which we want to compute the eigenvalue-eigenvector pairs for a handful of the largest (or smallest) eigenvalues.</p>
<p><code class="docutils literal notranslate"><span class="pre">scipy.sparse.linalg</span></code> wraps <a class="reference external" href="https://www.caam.rice.edu/software/ARPACK/">ARPACK (ARnoldi PACKage)</a>, which uses Krylov subspace techniques (like the iterative methods) to compute eigenvalues/eigenvectors using matrix-vector multiplications.  The relevant methods are <code class="docutils literal notranslate"><span class="pre">sla.eigs</span></code> (for general square matrices) and <code class="docutils literal notranslate"><span class="pre">sla.eigsh</span></code> (for symmetric/Hermitian matrices).  There is also a <code class="docutils literal notranslate"><span class="pre">sla.svds</span></code> function for the SVD.</p>
<p>Let’s look at an example for a linear operator which acts as the matrix of all ones.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># works on square matrices</span>
<span class="n">Afun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span> <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">m</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># linear operator of size 10</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">LinearOperator</span><span class="p">(</span>
    <span class="n">shape</span>   <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">m</span><span class="p">),</span>
    <span class="n">matvec</span>  <span class="o">=</span> <span class="n">Afun</span><span class="p">,</span>
    <span class="n">rmatvec</span> <span class="o">=</span> <span class="n">Afun</span><span class="p">,</span>
    <span class="n">matmat</span>  <span class="o">=</span> <span class="n">Afun</span><span class="p">,</span>
    <span class="n">rmatmat</span> <span class="o">=</span> <span class="n">Afun</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span>   
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This operator is Hermitian, so we’ll use <code class="docutils literal notranslate"><span class="pre">eigsh</span></code>.  By default, <code class="docutils literal notranslate"><span class="pre">eigsh</span></code> will compute the largest magnitude eigenvalues.  You can change which eigenvalues you’re looking for using the <code class="docutils literal notranslate"><span class="pre">which</span></code> keyword argument, and the number of eigenvalues using the <code class="docutils literal notranslate"><span class="pre">k</span></code> argument.  See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.eigsh.html#scipy.sparse.linalg.eigsh">the documentation</a> for details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lam</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">sla</span><span class="o">.</span><span class="n">eigsh</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Lam</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([-5.86174617e-18, -3.50871500e-32,  2.38837756e-32,  2.87286167e-32,
        1.78221859e-15,  1.00000000e+01])
</pre></div>
</div>
</div>
</div>
<p>we see there is one eigenvalue with a numerically non-zero value (10).  Let’s take a look at the eigenvector</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">V</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([-0.31622777, -0.31622777, -0.31622777, -0.31622777, -0.31622777,
       -0.31622777, -0.31622777, -0.31622777, -0.31622777, -0.31622777])
</pre></div>
</div>
</div>
</div>
<p>this is the vector with constant entries.  This agrees with our understanding of the operator <code class="docutils literal notranslate"><span class="pre">A</span></code>, which can be expressed as the symmetric rank-1 outer product of the vector with 1s in every entry.</p>
</div>
<div class="section" id="randomized-linear-algebra">
<h2>Randomized Linear Algebra<a class="headerlink" href="#randomized-linear-algebra" title="Permalink to this headline">¶</a></h2>
<p>In the past decade or two, randomized linear algebra has matured as a topic with lots of practical applications.  To read about the theory, see the 2009 paper by Halko, Martinsson, and Tropp: <a class="reference external" href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Link</a>.</p>
<p>SciPy does not (currently) have built-in functions for randomized linear algebra functionality (some languages like Julia do).  Fortunately, these algorithms are very easy to implement without worrying too much about the theory.</p>
<p>For simplicity, we’ll assume that <code class="docutils literal notranslate"><span class="pre">A</span></code> is symmetric with distinct eigenvectors, so we can limit the discussion to eigenvectors.  A rank-<code class="docutils literal notranslate"><span class="pre">k</span></code> approximation of <code class="docutils literal notranslate"><span class="pre">A</span></code> is an approximation by a rank-<code class="docutils literal notranslate"><span class="pre">k</span></code> outer product.  We can analyitically obtain the optimal rank-<code class="docutils literal notranslate"><span class="pre">k</span></code> approximation by computing a full eigenvalue decomposition of <code class="docutils literal notranslate"><span class="pre">A</span></code> and set all the eigenvalues outside the largest <code class="docutils literal notranslate"><span class="pre">k</span></code> (in magnitude) to 0.  Again, we don’t want to actually compute the full eigenvalue decomposition, so we want an algorithm that does this in some provable way.</p>
<p>The basic idea is to get an approximation of the range of an operator <code class="docutils literal notranslate"><span class="pre">A</span></code> by applying it to a bunch of random vectors. That is, we compute <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">X</span></code>, where <code class="docutils literal notranslate"><span class="pre">X</span></code> is a matrix with random entries (we think of every column as a random vector). One way to think about the action of <code class="docutils literal notranslate"><span class="pre">A</span></code> is that it “rotates” these random vectors preferentially in the direction of the top eigenvectors, so if we look at the most important subspace of the span of the image  <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">X</span></code> (as measured by the svd), we get a good approximation of the most important eigenspace.</p>
<p>Randomized algorithms have probabilistic gurarantees.  The statement is roughly that if entries of <code class="docutils literal notranslate"><span class="pre">X</span></code> are iid sub-Gaussian random variables (you can replace “sub-Gaussian” with Gaussian), and if we use <code class="docutils literal notranslate"><span class="pre">k+p</span></code> random vectors (<code class="docutils literal notranslate"><span class="pre">p</span></code> is a small constant), we can get close to the top-<code class="docutils literal notranslate"><span class="pre">k</span></code> dimensional eigenspace <em>with high probability</em>.  In this case, <em>close</em> depends on something called the spectral gap, and <em>with high probability</em> means that in order to <strong>not</strong> be close to the desired subspace you would likely need to keep running computations with different random numbers for millions or billions of years before you would observe the algorithm fail.</p>
<p>Let’s see how this works in practice:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.linalg</span> <span class="k">as</span> <span class="nn">la</span>

<span class="k">def</span> <span class="nf">random_span_k</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute subspace whose span is close to contaning the top-k eigenspace of A</span>
<span class="sd">    </span>
<span class="sd">    p = number of dimensions to pad</span>
<span class="sd">    power : number of times to run a power iteration on the subspace</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span>
        
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="n">p</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">X</span>
    
    <span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">power</span><span class="p">):</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">U</span>
        <span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    
    <span class="k">return</span> <span class="n">U</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s test this on a diagonal matrix with entries 0 to <code class="docutils literal notranslate"><span class="pre">n-1</span></code> along the main diagonal.  In this case, the eigenvalues are integers, and the eigenvectors are the standard basis vectors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">dia_matrix</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">))</span>
<span class="n">D</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;100x100 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 100 stored elements (1 diagonals) in DIAgonal format&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">random_span_k</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lam</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span>
<span class="n">V_true</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span><span class="o">-</span><span class="n">k</span><span class="p">:]</span>
<span class="n">V_true</span><span class="p">[</span><span class="o">-</span><span class="n">k</span><span class="p">:,:]</span> <span class="c1"># should see identity</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 1.]])
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at how well <code class="docutils literal notranslate"><span class="pre">U</span></code> captures each eigenvector.  The distance from this subspace from the <code class="docutils literal notranslate"><span class="pre">i</span></code>th eigenvector is <code class="docutils literal notranslate"><span class="pre">norm(V[:,i].T*U)</span></code>.  Because the eigenvectors are canonical basis vectors, this is just the norm of the <code class="docutils literal notranslate"><span class="pre">i</span></code>th row of <code class="docutils literal notranslate"><span class="pre">U</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:02d}</span><span class="s2"> : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>00 : 1.4933742633009502e-16
01 : 0.005441394458654931
02 : 0.01868615403013392
03 : 0.02382731090669485
04 : 0.04757093942906282
05 : 0.04339531062826645
06 : 0.058375943867943085
07 : 0.08239919543627812
08 : 0.05198911844319186
09 : 0.056466592512910016
10 : 0.08141185597772223
11 : 0.11684893621516558
12 : 0.08638823494057589
13 : 0.13818245000377
14 : 0.08794883577500576
15 : 0.16559556322440605
16 : 0.1380928023385035
17 : 0.13625229283724818
18 : 0.07309086625377473
19 : 0.15901732362759824
20 : 0.19387488190310967
21 : 0.21588279226001864
22 : 0.19520149505343715
23 : 0.1763265674926125
24 : 0.1943204640697035
25 : 0.21150578618090826
26 : 0.21416187324316355
27 : 0.27944967968754475
28 : 0.2729847662774293
29 : 0.28421265399891277
30 : 0.19282776875131716
31 : 0.19909451639849557
32 : 0.24294098494976218
33 : 0.2444092312772507
34 : 0.24290159897092709
35 : 0.3343869598981445
36 : 0.23957777884561215
37 : 0.28309157713944977
38 : 0.3076394397027184
39 : 0.3133708896627362
40 : 0.3397319410194627
41 : 0.3087721879121935
42 : 0.30402468427327195
43 : 0.2567903892870846
44 : 0.29578617127202167
45 : 0.3220969062280143
46 : 0.34422700621818886
47 : 0.27371269846300567
48 : 0.3802134041558566
49 : 0.3629432167543365
50 : 0.4235959768469325
51 : 0.35493989867273923
52 : 0.3632589975783833
53 : 0.4227902437457326
54 : 0.3524756393005297
55 : 0.35795513642356497
56 : 0.4426519838033534
57 : 0.4468619575540339
58 : 0.4666106048956708
59 : 0.37597401458041274
60 : 0.37524662287196725
61 : 0.41784343131180784
62 : 0.40622193175816507
63 : 0.42446751659146204
64 : 0.5340092732476752
65 : 0.35904623965890653
66 : 0.5100549014564097
67 : 0.44435598863283765
68 : 0.5799317863816683
69 : 0.39223976438456154
70 : 0.4656036660646256
71 : 0.35136762738484356
72 : 0.474881747333358
73 : 0.514845267680775
74 : 0.5513475766682286
75 : 0.5293692595421098
76 : 0.41381912429659035
77 : 0.5233437022820729
78 : 0.5213252495765238
79 : 0.5235214401256822
80 : 0.4882337530796311
81 : 0.47937330645039333
82 : 0.5866055069579232
83 : 0.5953792167367294
84 : 0.6243069392980906
85 : 0.3979529473751381
86 : 0.5117191110233087
87 : 0.7089276870545355
88 : 0.5485978587159839
89 : 0.5693782499780703
90 : 0.5637430063445522
91 : 0.530091076092731
92 : 0.5749947073891016
93 : 0.4921194132890199
94 : 0.4923744222228624
95 : 0.7710681975029314
96 : 0.3453847410367975
97 : 0.6521707757198328
98 : 0.6631944795961984
99 : 0.6613634951571074
</pre></div>
</div>
</div>
</div>
<p>As we see, <code class="docutils literal notranslate"><span class="pre">U</span></code> is closer to the larger eigenvectors, rather than the smaller eigenvectors.</p>
<p>We can improve this estimate by running a couple of power iterations on the subspace (the <code class="docutils literal notranslate"><span class="pre">power</span></code> keyword defined above):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">U</span> <span class="o">=</span> <span class="n">random_span_k</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:02d}</span><span class="s2"> : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>00 : 9.977676441154049e-17
01 : 2.3404109087672112e-12
02 : 1.5064531382856264e-10
03 : 1.6040006596282992e-09
04 : 1.0450264085473275e-08
05 : 3.632933397382902e-08
06 : 9.57511138496579e-08
07 : 3.776559838295419e-07
08 : 7.024083917399567e-07
09 : 2.4994126820494208e-06
10 : 3.6332714587604916e-06
11 : 3.367272919176564e-06
12 : 5.244709222193668e-06
13 : 1.2599823613253935e-05
14 : 1.7339525719891537e-05
15 : 2.3644229382315005e-05
16 : 5.268703832801706e-05
17 : 6.0513750780008226e-05
18 : 0.00013748989559806345
19 : 0.00014751388376007166
20 : 0.00011383589727542423
21 : 0.00015541826723960666
22 : 0.00030053745786550265
23 : 0.00042754313420309076
24 : 0.0006817344326876171
25 : 0.000947869990620443
26 : 0.0006480201001414219
27 : 0.000814238445991003
28 : 0.0007113285313195078
29 : 0.0020383931579025356
30 : 0.002462099018447307
31 : 0.002850335574406165
32 : 0.002695077184045343
33 : 0.004450664006180098
34 : 0.005528922413561093
35 : 0.0035594825863540513
36 : 0.006628149275121748
37 : 0.005928893082813755
38 : 0.007067582121588707
39 : 0.00955392806481757
40 : 0.011250623046576045
41 : 0.01861917523378968
42 : 0.013374249838051435
43 : 0.020601163083612557
44 : 0.02815974321391191
45 : 0.01773791838192479
46 : 0.03457830659496651
47 : 0.02543707945264898
48 : 0.025527470706159076
49 : 0.025842558150088277
50 : 0.050701384057636134
51 : 0.05301499654396797
52 : 0.06532164788327068
53 : 0.05903718316691118
54 : 0.05640866412569656
55 : 0.04965823975396068
56 : 0.09124167825913262
57 : 0.06827559460562427
58 : 0.0887053079461546
59 : 0.13417986332499474
60 : 0.13899906174469012
61 : 0.1179817095065959
62 : 0.11896059687109424
63 : 0.20378263075380001
64 : 0.15554983366202865
65 : 0.2288850286188974
66 : 0.1341020447110737
67 : 0.23642107962920697
68 : 0.22402835948764743
69 : 0.32121460960590353
70 : 0.25397902986483467
71 : 0.26869170363217854
72 : 0.4202044162094059
73 : 0.4308350347185242
74 : 0.4779571401372701
75 : 0.4432823262656937
76 : 0.4722413412098005
77 : 0.5191727772422405
78 : 0.6081786584985107
79 : 0.442170676199606
80 : 0.42007723574885913
81 : 0.7362322201327278
82 : 0.7337954188414755
83 : 0.7567632439328071
84 : 0.8170049160328803
85 : 0.6103210739064957
86 : 0.6188788475027888
87 : 0.8080221977574733
88 : 0.7503295033138141
89 : 0.7799753282112675
90 : 0.8856693711918322
91 : 0.9599930918962313
92 : 0.8254248285565422
93 : 0.8491577678590722
94 : 0.7009051658383769
95 : 0.862556448361447
96 : 0.8477828791198737
97 : 0.8794689382574724
98 : 0.9017924920901824
99 : 0.9144232041304529
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p>Download a couple of test matrices from the UFlorida Sparse Matrix collection <a class="reference external" href="https://sparse.tamu.edu/">Link</a>
For, example, use <code class="docutils literal notranslate"><span class="pre">mnist_test_norm_10NN</span></code> <a class="reference external" href="https://sparse.tamu.edu/ML_Graph/mnist_test_norm_10NN">Link</a> which would probably be too large to store on your computer as a dense matrix.</p>
<p>For each square matrix:</p>
<ol class="simple">
<li><p>Solve a random linear system using <code class="docutils literal notranslate"><span class="pre">splu</span></code></p></li>
<li><p>Solve a random linear system using either <code class="docutils literal notranslate"><span class="pre">minres</span></code> or <code class="docutils literal notranslate"><span class="pre">gmres</span></code> (which one should you use?)</p></li>
<li><p>Compute the largest magnitude eigenvector using <code class="docutils literal notranslate"><span class="pre">eigs</span></code> or <code class="docutils literal notranslate"><span class="pre">eigsh</span></code> (which one should you use?)</p></li>
</ol>
<p>Find a non-square matrix and</p>
<ol class="simple">
<li><p>Solve a random least squares problem using <code class="docutils literal notranslate"><span class="pre">lsqr</span></code></p></li>
<li><p>Compute the largest singular vectors using <code class="docutils literal notranslate"><span class="pre">svds</span></code></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">## Your code here</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "pycourse"
        },
        kernelOptions: {
            kernelName: "pycourse",
            path: "./02_linear_algebra"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'pycourse'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="linearoperators.html" title="previous page">Linear Operators</a>
    <a class='right-next' id="next-link" href="pytorch.html" title="next page">Linear Algebra in PyTorch</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Brad Nelson<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>