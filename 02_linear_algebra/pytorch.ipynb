{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra in PyTorch\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is a popular package for developing models for deep learning.  In this section, we'll look at its linear algebra capabilities.\n",
    "\n",
    "Even if you are not doing deep learning, you can use PyTorch for linear algebra.  One of the nice things about PyTorch is that it makes it easy to take advantage of GPU hardware, which is very efficient at certain operations.\n",
    "\n",
    "You can find [PyTorch tutorials](https://pytorch.org/tutorials/) on the official website as well as [documentation](https://pytorch.org/docs/stable/index.html).  Note these tutorials are focused on deep learning.  This section will focus on the linear algebra capabilities.\n",
    "\n",
    "When you install PyTorch, use the `pytorch` channel in conda.\n",
    "\n",
    "```bash\n",
    "conda install pytorch -c pytorch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tensors\n",
    "\n",
    "PyTorch `Tensor`s are just multi-dimensional arrays.  You can go back and forth between these and numpy `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11806299, 0.74761462],\n",
       "       [0.25475287, 0.65000852]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.rand(2,2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1181, 0.7476],\n",
       "        [0.2548, 0.6500]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.Tensor(A)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put a tensor on gpu, use `cuda()`.  Note that you must have an NVIDIA GPU in your computer to be able to do this successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1181, 0.7476],\n",
      "        [0.2548, 0.6500]], device='cuda:0')\n",
      "tensor([[0.1181, 0.7476],\n",
      "        [0.2548, 0.6500]])\n"
     ]
    }
   ],
   "source": [
    "Bcuda = B.cuda()\n",
    "print(Bcuda)\n",
    "Bcpu = B.cpu()\n",
    "print(Bcpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1181, 0.7476],\n",
       "        [0.2548, 0.6500]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.to(device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To move a tensor back to CPU, you can use `device='cpu'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra Functions\n",
    "\n",
    "PyTorch provides access to a variety of BLAS and LAPACK-type routines - see [documentation here](https://pytorch.org/docs/stable/torch.html#blas-and-lapack-operations).  These do not follow the BLAS/LAPACK naming conventions\n",
    "\n",
    "[`torch.addmv`](https://pytorch.org/docs/stable/generated/torch.addmv.html#torch-addmv) is roughly equivalent to `axpy`, and performs $Ax + y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "n = 100\n",
    "device = torch.device('cuda') # 'cuda' or 'cpu'\n",
    "\n",
    "Anp = np.random.randn(m,n)\n",
    "xnp = np.random.randn(n)\n",
    "ynp = np.random.randn(m)\n",
    "\n",
    "A = torch.Tensor(Anp).to(device=device)\n",
    "x = torch.Tensor(xnp).to(device=device)\n",
    "y = torch.Tensor(ynp).to(device=device)\n",
    "\n",
    "z = torch.addmv(y, A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the timing difference between CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy\n",
      "CPU times: user 3.62 ms, sys: 0 ns, total: 3.62 ms\n",
      "Wall time: 853 µs\n",
      "\n",
      "device = cpu\n",
      "CPU times: user 1.2 ms, sys: 0 ns, total: 1.2 ms\n",
      "Wall time: 352 µs\n",
      "\n",
      "device = cuda\n",
      "CPU times: user 193 µs, sys: 43 µs, total: 236 µs\n",
      "Wall time: 63.9 µs\n"
     ]
    }
   ],
   "source": [
    "m = 1000\n",
    "n = 1000\n",
    "\n",
    "Anp = np.random.randn(m,n)\n",
    "xnp = np.random.randn(n)\n",
    "ynp = np.random.randn(m)\n",
    "print(\"numpy\")\n",
    "%time z = ynp + Anp @ xnp\n",
    "\n",
    "\n",
    "for device in ('cpu', 'cuda'):\n",
    "    print(f\"\\ndevice = {device}\")\n",
    "    A = torch.Tensor(Anp).to(device=device)\n",
    "    x = torch.Tensor(xnp).to(device=device)\n",
    "    y = torch.Tensor(ynp).to(device=device)\n",
    "    z = torch.addmv(y, A, x)\n",
    "\n",
    "    %time z = torch.addmv(y, A, x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`torch.mv`](https://pytorch.org/docs/stable/generated/torch.mv.html#torch.mv) performs matrix-vector products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy\n",
      "CPU times: user 3.53 ms, sys: 0 ns, total: 3.53 ms\n",
      "Wall time: 812 µs\n",
      "\n",
      "device = cpu\n",
      "CPU times: user 1.66 ms, sys: 0 ns, total: 1.66 ms\n",
      "Wall time: 538 µs\n",
      "\n",
      "device = cuda\n",
      "CPU times: user 265 µs, sys: 51 µs, total: 316 µs\n",
      "Wall time: 90.4 µs\n"
     ]
    }
   ],
   "source": [
    "Anp = np.random.randn(m,n)\n",
    "xnp = np.random.randn(n)\n",
    "\n",
    "print(\"numpy\")\n",
    "%time z = Anp @ xnp\n",
    "\n",
    "\n",
    "for device in ['cpu', 'cuda']:\n",
    "    print(f\"\\ndevice = {device}\")\n",
    "    A = torch.Tensor(Anp).to(device=device)\n",
    "    x = torch.Tensor(xnp).to(device=device)\n",
    "    y = torch.mv(A, x)\n",
    "\n",
    "    %time y = torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[torch.mm](https://pytorch.org/docs/stable/generated/torch.mm.html#torch.mm) performs matrix-matrix multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy\n",
      "CPU times: user 112 ms, sys: 4.44 ms, total: 116 ms\n",
      "Wall time: 32.3 ms\n",
      "\n",
      "device = cpu\n",
      "CPU times: user 53.2 ms, sys: 0 ns, total: 53.2 ms\n",
      "Wall time: 13.5 ms\n",
      "\n",
      "device = cuda\n",
      "CPU times: user 124 µs, sys: 20 µs, total: 144 µs\n",
      "Wall time: 39.6 µs\n"
     ]
    }
   ],
   "source": [
    "m = 1000\n",
    "n = 1000\n",
    "\n",
    "Anp = np.random.randn(m,n)\n",
    "Bnp = np.random.randn(n, n)\n",
    "\n",
    "print(\"numpy\")\n",
    "%time C = Anp @ Bnp\n",
    "\n",
    "for device in ['cpu', 'cuda']:\n",
    "    print(f\"\\ndevice = {device}\")\n",
    "    A = torch.Tensor(Anp).to(device=device)\n",
    "    B = torch.Tensor(Bnp).to(device=device)\n",
    "    C = torch.mm(A, B) # run once to warm up\n",
    "\n",
    "    %time C = torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch operations\n",
    "\n",
    "Where PyTorch (and GPUs in general) really shine are in **batch** operations.  We get extra efficiency if we do a bunch of multiplications with matrices of the same size.\n",
    "\n",
    "For matrix-matrix multiplcation, the function is [`torch.bmm`](https://pytorch.org/docs/stable/generated/torch.bmm.html#torch.bmm)\n",
    "\n",
    "Because tensors are row-major, we want the batch index to be the first index.  In the below code, the batch multiplication is equivalent to\n",
    "```python\n",
    "for i in range(k):\n",
    "    C[i] = A[i] @ B[i]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy\n",
      "CPU times: user 378 ms, sys: 66.7 ms, total: 444 ms\n",
      "Wall time: 113 ms\n",
      "\n",
      "device = cpu\n",
      "CPU times: user 206 ms, sys: 14.5 ms, total: 221 ms\n",
      "Wall time: 56.4 ms\n",
      "\n",
      "device = cuda\n",
      "CPU times: user 350 µs, sys: 43 µs, total: 393 µs\n",
      "Wall time: 398 µs\n"
     ]
    }
   ],
   "source": [
    "n = 512 # matrix size\n",
    "k = 32 # batch size\n",
    "\n",
    "Anp = np.random.randn(k, n, n)\n",
    "Bnp = np.random.randn(k, n, n)\n",
    "# see numpy matmul documentation for how this performs batch multiplication\n",
    "print(\"numpy\")\n",
    "%time C = np.matmul(Anp, Bnp)\n",
    "\n",
    "for device in ['cpu', 'cuda']:\n",
    "    print(f\"\\ndevice = {device}\")\n",
    "    A = torch.randn(k, n, n).to(device=device)\n",
    "    B = torch.randn(k, n, n).to(device=device)\n",
    "    C = torch.bmm(A, B) # run once to warm up\n",
    "\n",
    "    %time C = torch.bmm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Linear Algebra\n",
    "\n",
    "PyTorch also supports sparse tensors in [`torch.sparse`](https://pytorch.org/docs/stable/sparse.html).  Tensors are stored in [COOrdinate format](sparse.html#coordinate-format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3.],\n",
       "        [4., 0., 5.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.LongTensor([[0, 1, 1],\n",
    "                      [2, 0, 2]])\n",
    "v = torch.FloatTensor([3, 4, 5])\n",
    "torch.sparse.FloatTensor(i, v, torch.Size([2,3])).to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indices are stored in a `2 x nnz` tensor of `Long` (a datatype that stores integers).  Values are stored as floats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a function that returns a sparse identity matrix of size `n` in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pycourse)",
   "language": "python",
   "name": "pycourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
